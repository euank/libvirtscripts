# vim: et:ts=2
storage:
  files:
  - filesystem: root
    mode: 420
    path: /etc/kubernetes/ssl/ca.pem
    contents:
      inline: |-
{{ .k8sCa | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/ca-root.pem
    contents:
      inline: |-
{{ .k8sCaRoot | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/ca-key.pem
    contents:
      inline: |-
{{ .k8sCaKey | indent 8}}
  - filesystem: root
    mode: 420
    path: /etc/kubernetes/ssl/apiserver.pem
    contents:
      inline: |-
{{ .k8sApiserverPem | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/apiserver-key.pem
    contents:
      inline: |-
{{ .k8sApiserverKey | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/kube-apiserver-token.csv
    contents:
      inline: |-
        {{ .bootstrapToken }},kubelet-bootstrap,10001,system:kubelet-bootstrap
  - filesystem: root
    path: /etc/flannel/options.env
    mode: 420
    contents:
      inline: |-
        FLANNELD_IFACE={{ .internalIP }}
        FLANNELD_ETCD_ENDPOINTS={{ .flannelEtcdEndpoints }}
  - filesystem: root
    path: /etc/kubernetes/cni/net.d/10-flannel.conf
    mode: 420
    contents:
      inline: |-
        {
          "name": "cniflannel",
          "type": "flannel",
          "delegate": {
            "isDefaultGateway": true
          }
        }
  - filesystem: root
    path: /etc/kubernetes/manifests/kube-proxy.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-proxy
          namespace: kube-system
        spec:
          hostNetwork: true
          containers:
          - name: kube-proxy
            image: quay.io/coreos/hyperkube:{{ .kubeletVersion }}
            command:
            - /hyperkube
            - proxy
            - --cluster-cidr=10.2.0.0/16
            - --master=http://127.0.0.1:8080
            securityContext:
              privileged: true
            volumeMounts:
              - mountPath: /etc/ssl/certs
                name: "ssl-certs"
          volumes:
            - name: "ssl-certs"
              hostPath:
                path: "/usr/share/ca-certificates"
  - filesystem: root
    path: /etc/kubernetes/manifests/kube-scheduler.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-scheduler
          namespace: kube-system
	  labels:
	    k8s-app: kube-scheduler
        spec:
          hostNetwork: true
          containers:
          - name: kube-scheduler
            image: quay.io/coreos/hyperkube:{{ .kubeletVersion }}
            command:
            - /hyperkube
            - scheduler
            - --master=http://127.0.0.1:8080
            - --leader-elect=true
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 10251
              initialDelaySeconds: 15
              timeoutSeconds: 1
  - filesystem: root
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-apiserver
          namespace: kube-system
        spec:
          hostNetwork: true
          containers:
          - name: kube-apiserver
            image: quay.io/coreos/hyperkube:{{ .kubeletVersion }}
            command:
            - /hyperkube
            - apiserver
            - --anonymous-auth=false
            - --bind-address=0.0.0.0
            - --etcd-servers=http://192.168.131.3:2379,http://192.168.131.4:2379,http://192.168.131.5:2379
            - --allow-privileged=true
            - --service-cluster-ip-range=10.3.0.0/24
            - --secure-port=443
            - --kubelet-preferred-address-types=InternalIP
            - --advertise-address={{.internalIP}}
            - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota
            - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
            - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
            - --client-ca-file=/etc/kubernetes/ssl/ca.pem
            - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
            - --runtime-config=extensions/v1beta1=true,extensions/v1beta1/networkpolicies=true
            - --token-auth-file=/etc/kubernetes/ssl/kube-apiserver-token.csv
            ports:
            - containerPort: 443
              hostPort: 443
              name: https
            - containerPort: 8080
              hostPort: 8080
              name: local
            volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
            - mountPath: /etc/ssl/certs
              name: ssl-certs-host
              readOnly: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host

  - filesystem: root
    path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-controller-manager
          namespace: kube-system
	  labels:
	    k8s-app: kube-controller-manager
        spec:
          hostNetwork: true
          containers:
          - name: kube-controller-manager
            image: quay.io/coreos/hyperkube:{{ .kubeletVersion }}
            command:
            - /hyperkube
            - controller-manager
            - --master=http://127.0.0.1:8080
            - --leader-elect=true
            - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
            - --root-ca-file=/etc/kubernetes/ssl/ca.pem
            - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca-root.pem
            - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem
            - --insecure-experimental-approve-all-kubelet-csrs-for-group=system:kubelet-bootstrap
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 10252
              initialDelaySeconds: 15
              timeoutSeconds: 1
            volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
            - mountPath: /etc/ssl/certs
              name: ssl-certs-host
              readOnly: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host

  - filesystem: root
    path: /var/lib/iptables/rules-save
    mode: 420
    contents:
      inline: |-
        *filter
        :INPUT DROP [0:0]
        :FORWARD DROP [0:0]
        :OUTPUT ACCEPT [0:0]
        -A INPUT -i lo -j ACCEPT
        -A INPUT -i eth1 -j ACCEPT
        -A INPUT -i cni0 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 222 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT
        -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
        -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT
        -A FORWARD -i cni0 -j ACCEPT
        -A FORWARD -o cni0 -j ACCEPT
        COMMIT
        # EOF
  - filesystem: root
    path: /var/lib/ip6tables/rules-save
    mode: 420
    contents:
      inline: |-
        *filter
        :INPUT DROP [0:0]
        :FORWARD DROP [0:0]
        :OUTPUT ACCEPT [0:0]
        -A INPUT -i lo -j ACCEPT
        -A INPUT -i eth1 -j ACCEPT
        -A INPUT -i cni0 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 222 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT
        -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
        -A INPUT -p ipv6-icmp -j ACCEPT
        -A FORWARD -i cni0 -j ACCEPT
        -A FORWARD -o cni0 -j ACCEPT
        COMMIT
        # EOF
  - filesystem: root
    path: /etc/hostname
    mode: 420
    contents:
      inline: |-
        {{ .hostname }}
  - filesystem: root
    path: /etc/ssh/sshd_config
    mode: 420
    contents:
      inline: |-
        # From: https://wiki.mozilla.org/Security/Guidelines/OpenSSH#Modern_.28OpenSSH_6.7.2B.29
        # Supported HostKey algorithms by order of preference.
        HostKey /etc/ssh/ssh_host_ed25519_key
        HostKey /etc/ssh/ssh_host_rsa_key
        HostKey /etc/ssh/ssh_host_ecdsa_key
         
        KexAlgorithms curve25519-sha256@libssh.org,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256,diffie-hellman-group-exchange-sha256
         
        Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com,aes256-ctr,aes192-ctr,aes128-ctr
         
        MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-sha2-256,umac-128@openssh.com
         
        # Password based logins are disabled - only public key based logins are allowed.
        AuthenticationMethods publickey
         
        # LogLevel VERBOSE logs user's key fingerprint on login. Needed to have a clear audit track of which key was using to log in.
        LogLevel VERBOSE
         
        # Log sftp level file access (read/write/etc.) that would not be easily logged otherwise.
        Subsystem sftp  /usr/lib/ssh/sftp-server -f AUTHPRIV -l INFO
         
        # Root login is not allowed for auditing reasons. This is because it's difficult to track which process belongs to which root user:
        #
        # On Linux, user sessions are tracking using a kernel-side session id, however, this session id is not recorded by OpenSSH.
        # Additionally, only tools such as systemd and auditd record the process session id.
        # On other OSes, the user session id is not necessarily recorded at all kernel-side.
        # Using regular users in combination with /bin/su or /usr/bin/sudo ensure a clear audit track.
        PermitRootLogin No
         
        # Use kernel sandbox mechanisms where possible in unprivilegied processes
        # Systrace on OpenBSD, Seccomp on Linux, seatbelt on MacOSX/Darwin, rlimit elsewhere.
        UsePrivilegeSeparation sandbox 
        Port 222
        AllowUsers core
systemd:
  units:
  - name: flanneld.service
    enable: true
    dropins:
    - name: 10-options.conf
      contents: |-
        [Service]
        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env
  - name: docker.service
    enable: true
    dropins:
    - name: 40-after-flannel.conf
      contents: |-
        [Unit]
        After=flanneld.service
  - name: kubelet.service
    enable: true
    contents: |-
      [Service]
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
      ExecStartPre=/usr/bin/mkdir -p /var/log/containers
      
      Environment=KUBELET_VERSION={{ .kubeletVersion }}
      Environment="RKT_OPTS=--volume var-log,kind=host,source=/var/log \
        --mount volume=var-log,target=/var/log \
        --volume dns,kind=host,source=/etc/resolv.conf \
        --mount volume=dns,target=/etc/resolv.conf"
      
      ExecStart=/usr/lib/coreos/kubelet-wrapper \
        --api-servers=http://127.0.0.1:8080 \
        --address={{ .internalIP }} \
        --node-ip={{ .internalIP }} \
        --read-only-port=0 \
        --network-plugin=cni \
        --require-kubeconfig=true \
        --cni-conf-dir=/etc/kubernetes/cni/net.d \
        --register-schedulable=false \
        --allow-privileged=true \
        --pod-manifest-path=/etc/kubernetes/manifests \
        --cluster-dns=10.3.0.10 \
        --cluster-domain=cluster.local \
      Restart=always
      RestartSec=10
      [Install]
      WantedBy=multi-user.target
  - name: update-engine.service
    mask: true
  - name: locksmithd.service
    mask: true
  - name: iptables-restore.service
    enable: true
  - name: iptables-store.service
    enable: true
  - name: ip6tables-restore.service
    enable: true
  - name: ip6tables-store.service
    enable: true
  - name: sshd.socket
    mask: true
  - name: sshd.service
    enable: true
  - name: docker.service
    enable: true
networkd:
  units:
  - name: xx-dhcp.network
    contents: |-
      # Attempt to work around https://github.com/systemd/systemd/issues/5625
      [Network]
      DHCP=ipv4
      IPv6AcceptRA=no
      LinkLocalAddressing=no


      [DHCP]
      UseMTU=true
      UseDomains=true
passwd:
  users:
  - name: core
    ssh_authorized_keys:
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCyeivCOXMLvMzKvZjPzNSqD8kvkbsI/Ecdxe7V7HZDG8AfliS68frOZI5pl0uqfBet80e5qH/njDvdfKpKuBiAgUZcBz1+LGdrCr+Tn8Bi0ypu+xSpjJjPT0fVgD9qk0lv5TnUmqZD/BZShQjlp6T0MfETSbGppTxRRZIS2CgjO230fktZST8GUJBX/G0HVupqVdbORVdBkbEx4XfJLrmI3HSuA2drlImhCegrByg8r6k2Q/256myWri8Q2X0bVIg93FqcuLGvngGL8kJinwo/zRPo5ucfH0DWsQWtHo6ayx2FycMsCmd56ZU+FH9PBy73ki4ACqsaGh+T8silAR5R yubikey1
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDMdxqFTG7bPey17ZWg6LbonqASSNJnlmdMg3yiYPuNu6/b4Ffe4iycGAwVl/ODKnEzLZ2aWUhiVrLMv4Z6vml3/l/qU3PPeQRe+TY0afXLbT05xDG2HS/y5SE/6qoynKb2FzJ8YCpI3xdoJ3E4L5+a5vZ1yjknaFcHcL0/g5GCsKo0QpO6dH9Tz+W36Ua/kGXmqMzDaOraXLvTc2TBJ4Mm/CRy6zL773V4GE5e+w4MxdYGpaGZ2EaKw37xFAyx2lH2/RbRt+qTsvGOjfhXuMyOEtsrDEkM7mbRdjuC8WzlutTrDESRJuVAu47HEZjMKCaQ05wgI/LYS3CeolorGDf9tahnjS5s0x7X+NIRkEA0qgpxUwr5T9Z7JKWIIOV90Rbu6CFEfhldNtfA5uD8RLufIiiQTsTZmHjHaPWi98iphb+wMpy8yB4lPPzoWfSuofPVcWaLFoFzGwKkP38XLyeKXEyUgGJPTLPLkGNjQgTBqZlOTL06UR8GNKPtWo5dMCvsFuz0+u34LaeyNg+2i7gvhWZakDZ1EAqWdtj6A+8oAlIEa04OR09xlfdjA9BMA4xGyq9sOKn99tV5qTIZl3X+MIxxPUm0TYXulM4kByeKROAvQhgwSUJAE63qVddBnl+PAsUZPREl8l/ccuytZIlnDn2RY0LlIXGYb0tIEykSqw== yubikey2

