# vim: et:ts=2
storage:
  files:
  - filesystem: root
    mode: 493
    path: /opt/bin/kubelet
    contents:
      remote:
        url: "https://storage.googleapis.com/kubernetes-release/release/v{{.kubeletVersion}}/bin/linux/amd64/kubelet"
        verification:
          hash:
            function: sha512
            sum: "{{.kubeletHash}}"
  - filesystem: root
    path: /opt/cni/plugins.tgz
    contents:
      remote:
        url: https://github.com/containernetworking/plugins/releases/download/v0.6.0/cni-plugins-amd64-v0.6.0.tgz
        verification:
          hash:
            function: sha512
            sum: "398afcb1bdac39b3c5113ef6e114b887827a3600a227cd5cef7d36eaea397670520f35b221907490ad78af81049629a321816ce834318749ef7e75d2ab12a5c4"
  - filesystem: root
    path: /etc/kubernetes/worker-bootstrap.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Config
        clusters:
        - name: kubernetes
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
            server: https://k8s-master.internal.k8s.euank.com
        users:
        - name: kubelet
          user:
            token: {{ .bootstrapToken }}
        contexts:
        - context:
            cluster: kubernetes
            user: kubelet
          name: kubelet-context
        current-context: kubelet-context
  - filesystem: root
    path: /etc/kubernetes/controllermanager-kubeconfig.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Config
        clusters:
        - name: kubernetes
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
            server: https://k8s-master.internal.k8s.euank.com
        users:
        - name: controllermanager
          user:
            client-certificate: /etc/kubernetes/ssl/controller.pem
            client-key: /etc/kubernetes/ssl/controller-key.pem
        contexts:
        - context:
            cluster: kubernetes
            user: controllermanager
          name: cm-ctx
        current-context: cm-ctx
  - filesystem: root
    path: /etc/kubernetes/scheduler-kubeconfig.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Config
        clusters:
        - name: kubernetes
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
            server: https://k8s-master.internal.k8s.euank.com
        users:
        - name: scheduler
          user:
            client-certificate: /etc/kubernetes/ssl/scheduler.pem
            client-key: /etc/kubernetes/ssl/scheduler-key.pem
        contexts:
        - context:
            cluster: kubernetes
            user: scheduler
          name: s-ctx
        current-context: s-ctx
  - filesystem: root
    mode: 420
    path: /etc/kubernetes/ssl/ca.pem
    contents:
      inline: |-
{{ .k8sCa | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/ca-root.pem
    contents:
      inline: |-
{{ .k8sCaRoot | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/ca-key.pem
    contents:
      inline: |-
{{ .k8sCaKey | indent 8}}
  - filesystem: root
    mode: 420
    path: /etc/kubernetes/ssl/apiserver.pem
    contents:
      inline: |-
{{ .k8sApiserverPem | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/apiserver-key.pem
    contents:
      inline: |-
{{ .k8sApiserverKey | indent 8}}
  - filesystem: root
    mode: 420
    path: /etc/kubernetes/ssl/controller.pem
    contents:
      inline: |-
{{ .k8sControllerPem | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/controller-key.pem
    contents:
      inline: |-
{{ .k8sControllerKey | indent 8}}
  - filesystem: root
    mode: 420
    path: /etc/kubernetes/ssl/scheduler.pem
    contents:
      inline: |-
{{ .k8sSchedulerPem | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/scheduler-key.pem
    contents:
      inline: |-
{{ .k8sSchedulerKey | indent 8}}
  - filesystem: root
    mode: 256
    path: /etc/kubernetes/ssl/kube-apiserver-token.csv
    contents:
      inline: |-
        {{ .bootstrapToken }},kubelet-bootstrap,10001,system:kubelet-bootstrap
  - filesystem: root
    path: /etc/kubernetes/manifests/kube-scheduler.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-scheduler
          namespace: kube-system
          labels:
            k8s-app: kube-scheduler
        spec:
          hostNetwork: true
          containers:
          - name: kube-scheduler
            image: gcr.io/google-containers/hyperkube-amd64:v{{ .kubeletVersion }}
            command:
            - /hyperkube
            - scheduler
            - --kubeconfig=/etc/kubernetes/scheduler-kubeconfig.yaml
            - --leader-elect=true
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 10251
              initialDelaySeconds: 15
              timeoutSeconds: 1
            volumeMounts:
              - mountPath: /etc/ssl/certs
                name: "ssl-certs"
              - mountPath: /etc/kubernetes/scheduler-kubeconfig.yaml
                name: "kubeconfig"
                readOnly: true
              - mountPath: /etc/kubernetes/ssl
                name: "etc-kube-ssl"
                readOnly: true
          volumes:
            - name: "ssl-certs"
              hostPath:
                path: "/usr/share/ca-certificates"
            - name: "kubeconfig"
              hostPath:
                path: "/etc/kubernetes/scheduler-kubeconfig.yaml"
            - name: "etc-kube-ssl"
              hostPath:
                path: "/etc/kubernetes/ssl"
  - filesystem: root
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-apiserver
          namespace: kube-system
        spec:
          hostNetwork: true
          containers:
          - name: kube-apiserver
            image: gcr.io/google-containers/hyperkube-amd64:v{{ .kubeletVersion }}
            command:
            - /hyperkube
            - apiserver
            - --anonymous-auth=false
            - --bind-address=0.0.0.0
            - --etcd-servers=http://192.168.131.3:2379
            - --allow-privileged=true
            - --authorization-mode=RBAC
            - --service-cluster-ip-range=10.3.0.0/24
            - --secure-port=443
            - --kubelet-preferred-address-types=InternalIP
            - --advertise-address={{.internalIP}}
            - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota
            - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
            - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
            - --client-ca-file=/etc/kubernetes/ssl/ca.pem
            - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
            - --runtime-config=extensions/v1beta1=true,extensions/v1beta1/networkpolicies=true
            - --token-auth-file=/etc/kubernetes/ssl/kube-apiserver-token.csv
            - --v=2
            ports:
            - containerPort: 443
              hostPort: 443
              name: https
            - containerPort: 8080
              hostPort: 8080
              name: local
            volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
            - mountPath: /etc/ssl/certs
              name: ssl-certs-host
              readOnly: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host
  - filesystem: root
    path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    mode: 420
    contents:
      inline: |-
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-controller-manager
          namespace: kube-system
          labels:
            k8s-app: kube-controller-manager
        spec:
          hostNetwork: true
          containers:
          - name: kube-controller-manager
            image: gcr.io/google-containers/hyperkube-amd64:v{{ .kubeletVersion }}
            command:
            - /hyperkube
            - controller-manager
            - --kubeconfig=/etc/kubernetes/controllermanager-kubeconfig.yaml
            - --leader-elect=true
            - --use-service-account-credentials
            - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
            - --root-ca-file=/etc/kubernetes/ssl/ca.pem
            - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca-root.pem
            - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 10252
              initialDelaySeconds: 15
              timeoutSeconds: 1
            volumeMounts:
              - mountPath: /etc/ssl/certs
                name: "ssl-certs"
              - mountPath: /etc/kubernetes/controllermanager-kubeconfig.yaml
                name: "kubeconfig"
                readOnly: true
              - mountPath: /etc/kubernetes/ssl
                name: "etc-kube-ssl"
                readOnly: true
          volumes:
            - name: "ssl-certs"
              hostPath:
                path: "/usr/share/ca-certificates"
            - name: "kubeconfig"
              hostPath:
                path: "/etc/kubernetes/controllermanager-kubeconfig.yaml"
            - name: "etc-kube-ssl"
              hostPath:
                path: "/etc/kubernetes/ssl"

  - filesystem: root
    path: /var/lib/iptables/rules-save
    mode: 420
    contents:
      inline: |-
        *filter
        :INPUT DROP [0:0]
        :FORWARD DROP [0:0]
        :OUTPUT ACCEPT [0:0]
        -A INPUT -i lo -j ACCEPT
        -A INPUT -i eth1 -j ACCEPT
        -A INPUT -i cni0 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 222 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT
        -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
        -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT
        -A FORWARD -i cni0 -j ACCEPT
        -A FORWARD -o cni0 -j ACCEPT
        COMMIT
        # EOF
  - filesystem: root
    path: /var/lib/ip6tables/rules-save
    mode: 420
    contents:
      inline: |-
        *filter
        :INPUT DROP [0:0]
        :FORWARD DROP [0:0]
        :OUTPUT ACCEPT [0:0]
        -A INPUT -i lo -j ACCEPT
        -A INPUT -i eth1 -j ACCEPT
        -A INPUT -i cni0 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 222 -j ACCEPT
        -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT
        -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
        -A INPUT -p ipv6-icmp -j ACCEPT
        -A FORWARD -i cni0 -j ACCEPT
        -A FORWARD -o cni0 -j ACCEPT
        COMMIT
        # EOF
  - filesystem: root
    path: /etc/hostname
    mode: 420
    contents:
      inline: |-
        {{ .hostname }}
  - filesystem: root
    path: /etc/docker/daemon.json
    mode: 420
    contents:
      inline: |-
        {
          "log-driver": "journald"
        }
  - filesystem: root
    path: /etc/ssh/sshd_config
    mode: 420
    contents:
      inline: |-
        # From: https://wiki.mozilla.org/Security/Guidelines/OpenSSH#Modern_.28OpenSSH_6.7.2B.29
        # Supported HostKey algorithms by order of preference.
        HostKey /etc/ssh/ssh_host_ed25519_key
        HostKey /etc/ssh/ssh_host_rsa_key
        HostKey /etc/ssh/ssh_host_ecdsa_key
         
        KexAlgorithms curve25519-sha256@libssh.org,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256,diffie-hellman-group-exchange-sha256
         
        Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com,aes256-ctr,aes192-ctr,aes128-ctr
         
        MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-sha2-256,umac-128@openssh.com
         
        # Password based logins are disabled - only public key based logins are allowed.
        AuthenticationMethods publickey
         
        # LogLevel VERBOSE logs user's key fingerprint on login. Needed to have a clear audit track of which key was using to log in.
        LogLevel VERBOSE
         
        # Log sftp level file access (read/write/etc.) that would not be easily logged otherwise.
        Subsystem sftp  /usr/lib/ssh/sftp-server -f AUTHPRIV -l INFO
         
        # Root login is not allowed for auditing reasons. This is because it's difficult to track which process belongs to which root user:
        #
        # On Linux, user sessions are tracking using a kernel-side session id, however, this session id is not recorded by OpenSSH.
        # Additionally, only tools such as systemd and auditd record the process session id.
        # On other OSes, the user session id is not necessarily recorded at all kernel-side.
        # Using regular users in combination with /bin/su or /usr/bin/sudo ensure a clear audit track.
        PermitRootLogin No
         
        # Use kernel sandbox mechanisms where possible in unprivilegied processes
        # Systrace on OpenBSD, Seccomp on Linux, seatbelt on MacOSX/Darwin, rlimit elsewhere.
        UsePrivilegeSeparation sandbox 
        Port 222
        AllowUsers core
systemd:
  units:
  - name: flanneld.service
    mask: true
  - name: rkt-gc.timer
    mask: true
  - name: kubelet.service
    enable: true
    contents: |-
      [Service]
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
      ExecStartPre=/usr/bin/mkdir -p /var/log/containers
      ExecStart=/opt/bin/kubelet \
        --kubeconfig=/etc/kubernetes/kubeconfig \
        --address={{ .internalIP }} \
        --node-ip={{ .internalIP }} \
        --cloud-provider="" \
        --read-only-port=0 \
        --network-plugin=cni \
        --cni-conf-dir=/etc/kubernetes/cni/net.d \
        --cni-bin-dir=/opt/cni \
        --register-with-taints=node-role.kubernetes.io/master=true:NoSchedule \
        --pod-manifest-path=/etc/kubernetes/manifests \
        --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
        --cert-dir=/etc/kubernetes/ssl \
        --bootstrap-kubeconfig=/etc/kubernetes/worker-bootstrap.yaml \
        --cluster-dns=10.3.0.10 \
        --cluster-domain=cluster.local
      Restart=always
      RestartSec=10
      [Install]
      WantedBy=multi-user.target
  - name: extract-cni.service
    enable: true
    contents: |-
      [Service]
      Type=oneshot
      RemainAfterExit=true
      ConditionPathExists=/opt/cni/plugins.tgz
      ExecStart=/usr/bin/tar -C /opt/cni -xf /opt/cni/plugins.tgz
      ExecStart=/usr/bin/rm -f /opt/cni/plugins.tgz
      [Install]
      WantedBy=multi-user.target
  - name: update-engine.service
    mask: true
  - name: locksmithd.service
    mask: true
  - name: iptables-restore.service
    enable: true
  - name: iptables-store.service
    enable: true
  - name: ip6tables-restore.service
    enable: true
  - name: ip6tables-store.service
    enable: true
  - name: sshd.socket
    mask: true
  - name: sshd.service
    enable: true
  - name: docker.service
    enable: true
networkd:
  units:
  - name: xx-dhcp.network
    contents: |-
      # Attempt to work around https://github.com/systemd/systemd/issues/5625
      [Network]
      DHCP=ipv4
      IPv6AcceptRA=no
      LinkLocalAddressing=no


      [DHCP]
      UseMTU=true
      UseDomains=true
passwd:
  users:
  - name: core
    ssh_authorized_keys:
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCyeivCOXMLvMzKvZjPzNSqD8kvkbsI/Ecdxe7V7HZDG8AfliS68frOZI5pl0uqfBet80e5qH/njDvdfKpKuBiAgUZcBz1+LGdrCr+Tn8Bi0ypu+xSpjJjPT0fVgD9qk0lv5TnUmqZD/BZShQjlp6T0MfETSbGppTxRRZIS2CgjO230fktZST8GUJBX/G0HVupqVdbORVdBkbEx4XfJLrmI3HSuA2drlImhCegrByg8r6k2Q/256myWri8Q2X0bVIg93FqcuLGvngGL8kJinwo/zRPo5ucfH0DWsQWtHo6ayx2FycMsCmd56ZU+FH9PBy73ki4ACqsaGh+T8silAR5R yubikey1
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDMdxqFTG7bPey17ZWg6LbonqASSNJnlmdMg3yiYPuNu6/b4Ffe4iycGAwVl/ODKnEzLZ2aWUhiVrLMv4Z6vml3/l/qU3PPeQRe+TY0afXLbT05xDG2HS/y5SE/6qoynKb2FzJ8YCpI3xdoJ3E4L5+a5vZ1yjknaFcHcL0/g5GCsKo0QpO6dH9Tz+W36Ua/kGXmqMzDaOraXLvTc2TBJ4Mm/CRy6zL773V4GE5e+w4MxdYGpaGZ2EaKw37xFAyx2lH2/RbRt+qTsvGOjfhXuMyOEtsrDEkM7mbRdjuC8WzlutTrDESRJuVAu47HEZjMKCaQ05wgI/LYS3CeolorGDf9tahnjS5s0x7X+NIRkEA0qgpxUwr5T9Z7JKWIIOV90Rbu6CFEfhldNtfA5uD8RLufIiiQTsTZmHjHaPWi98iphb+wMpy8yB4lPPzoWfSuofPVcWaLFoFzGwKkP38XLyeKXEyUgGJPTLPLkGNjQgTBqZlOTL06UR8GNKPtWo5dMCvsFuz0+u34LaeyNg+2i7gvhWZakDZ1EAqWdtj6A+8oAlIEa04OR09xlfdjA9BMA4xGyq9sOKn99tV5qTIZl3X+MIxxPUm0TYXulM4kByeKROAvQhgwSUJAE63qVddBnl+PAsUZPREl8l/ccuytZIlnDn2RY0LlIXGYb0tIEykSqw== yubikey2
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCyFcdo10FvG1lxiUKjccK2agmIIm13w0XmtftjI36q+7tg6ULrbFRdk/XITucTfSet/0y9Kup8QJM00i8k9EGD5SGcULhDX6p/mc0YTI1DeOHauAU3y7hlsE0a13sm5kg7XZ1dDqb5nY+8I6ZjHc5FlbjatAKHOSosljjIeOSvgg/tKJGf8qna4pzlgfhN4bf8jbK4ZJ6JoTVD9ulQqKKcwLdJFIxxKR4VxXVxGHiH8dvP3oPzhQ6W9GAc0yfBl8kIxJdzvEd5h7vX9b93ZFWolkkZYpyxbvapeeLmNX4e5TexWPUU1kT7jIi/rvTrSow5iYGu5rgwgqy6Ey37jhpQKQUgwkLPH1mt/9vg4WlpbPEk0TihDmW0yJ8CwHetZAs4cjSbiuMGopBf2rCEIrjyflKIiy/Of7MVp3NVEPVDOu3VEH/khxrHR5KC9XKOg4jhcsQBj0t+i1iJCmi981sXzXLHmmXZMNlcf0jFSG4TwApyc1+hJIBladsSZ12mLY1lFCTx/Yx3ztoNPqGPLAkNYuj3z50jL/Jdj2oVNcQqNpxb6bHmW416LcuUGQ9DSIJUJLxmv/CXW5Wpepm30KTumJSy6G6bBCe4b+Gw2g74K6uwjEaX2uGXNJvRNE+ftDf23fy1orO3HLncY23Du/R6iDcMj/coMMlkAES1AdxEFw==

